{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc61e652",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35_2023/blob/main/Session3/BMEN35_Ex8_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c73be4",
   "metadata": {
    "id": "d2c73be4"
   },
   "source": [
    "## Linear Regression\n",
    "In this notebook we will be looking into Linear Regression.\n",
    "\n",
    "Let us start by importing our usual suspects and generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac01678",
   "metadata": {
    "id": "bac01678"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lets start by making a simple example\n",
    "N = 500 # Number of datapoints\n",
    "X = 5 *np.random.rand(N,1)\n",
    "y =  2 - 3 * X + np.random.randn(N,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0103a8",
   "metadata": {
    "id": "ce0103a8"
   },
   "source": [
    "We want to examine this data and we can do that by plotting it. We will use a scatterplot for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b718e",
   "metadata": {
    "id": "ea5b718e"
   },
   "outputs": [],
   "source": [
    "# Lets make a scatter plot of the data to see what it looks like\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef81e3",
   "metadata": {
    "id": "beef81e3"
   },
   "source": [
    "We can try to guess intercept and slope by visual inspection here and see how well it correlates with the algorithm.\n",
    "\n",
    "Next we will start with the algorithm. We generated X and y but we need to add one column of ones for the intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e360c7",
   "metadata": {
    "id": "28e360c7"
   },
   "outputs": [],
   "source": [
    "# We add a column of ones for the intercept (theta0)\n",
    "X_b = np.hstack((np.ones([N,1]),X))\n",
    "\n",
    "# We can solve this problem now using equation 3.14 from the book, we do it step by step here\n",
    "a = np.dot(X_b.T,X_b)\n",
    "b = np.linalg.inv(a)\n",
    "c = np.dot(b, X_b.T)\n",
    "theta_a = np.dot(c,y)\n",
    "# Or we write it in one line\n",
    "theta_b = np.dot(np.dot(np.linalg.inv(np.dot(X_b.T,X_b)),X_b.T),y)\n",
    "# We can check that they are the same\n",
    "print(theta_a)\n",
    "print(theta_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8627f",
   "metadata": {
    "id": "d8e8627f"
   },
   "source": [
    "Lets plot the data again and add the \"regression\" line to the plot. Here we can calculate where two points are and make line between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d5582",
   "metadata": {
    "id": "a31d5582"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([0,5]) # These are X-values we will use\n",
    "X_new_b = np.array([[1,0],[1,5]]) # We also need the intercept term\n",
    "y_hat = np.dot(X_new_b, theta_b) # We calculate/predict the values of y_hat at x = 0, x = 5\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X_new, y_hat, 'r',linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba2dcb",
   "metadata": {
    "id": "4bba2dcb"
   },
   "source": [
    "That was all good.\n",
    "\n",
    "Next we will try \"polynomial regression\". We will make up some data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f537e",
   "metadata": {
    "id": "c79f537e"
   },
   "outputs": [],
   "source": [
    "N = 500 # Number of datapoints\n",
    "X = 10*np.random.rand(N,1) - 5\n",
    "y =  2 + 0.5 * X**2 + 3 * X + np.random.randn(N,1)\n",
    "\n",
    "# Lets make a scatter plot of the data to see what it looks like\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f5a8b",
   "metadata": {
    "id": "7a2f5a8b"
   },
   "source": [
    "Looks like it is not a straight line. We guess its a quadratic equation and start from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7ad01",
   "metadata": {
    "id": "46d7ad01"
   },
   "outputs": [],
   "source": [
    "# We add a column of ones for the intercept (theta0), the x^2 term and x\n",
    "X_b = np.hstack((np.ones([N,1]),X**2, X))\n",
    "# We can now solve this problem using equation 3.14 from the book\n",
    "theta = np.dot(np.dot(np.linalg.inv(np.dot(X_b.T,X_b)),X_b.T),y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da815d7a",
   "metadata": {
    "id": "da815d7a"
   },
   "source": [
    "Lets plot the data again and add the \"regression\" line. Here we cant cheat so we will make an array for x-values. Add intercept term, calculate y_hat and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acec96",
   "metadata": {
    "id": "d7acec96"
   },
   "outputs": [],
   "source": [
    "X_new = np.linspace(-5, 5, N).reshape(N, 1) # These are X-values we will use\n",
    "X_new_b = np.hstack((np.ones([N,1]),X_new**2, X_new)) # Add intercept and x^2 term\n",
    "y_hat = np.dot(X_new_b, theta) #\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X_new, y_hat, 'r', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e267a",
   "metadata": {
    "id": "691e267a"
   },
   "source": [
    "In the lecture you also talked about gradient descent. Lets try a version using that method. First some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f77e32",
   "metadata": {
    "id": "76f77e32"
   },
   "outputs": [],
   "source": [
    "N = 500 # Number of datapoints\n",
    "X = 5 *np.random.rand(N,1)\n",
    "y =  1.8 + 3.4 * X + np.random.randn(N,1)\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196683c",
   "metadata": {
    "id": "f196683c"
   },
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "eta = 0.01  # learning rate\n",
    "n_epochs = 20 # How many iterations / epochs\n",
    "theta0 = 0 # Start from zero number for\n",
    "theta1 =0\n",
    "cost = np.zeros(n_epochs)\n",
    "n = len(X)\n",
    "thetas = np.zeros((n_epochs,2)) # To save our estimated thetas\n",
    "for i in range(n_epochs):\n",
    "    y_hat = theta0 + theta1 * X # The current predicted value of Y\n",
    "    cost[i] = np.sum((y - y_hat)**2) / n\n",
    "    D_theta0 = (-2/n) * np.sum(y - y_hat)  # Derivative wrt theta0\n",
    "    D_theta1 = (-2/n) * np.sum(X * (y - y_hat))  # Derivative wrt theta1\n",
    "    theta0 = theta0 - eta * D_theta0  # Update theta0\n",
    "    theta1 = theta1 - eta * D_theta1  # Update theta1\n",
    "    thetas[i,:] = (theta0,theta1)\n",
    "\n",
    "print(thetas[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b080770",
   "metadata": {
    "id": "6b080770"
   },
   "source": [
    "Lets check what we get with our previous method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8851ed",
   "metadata": {
    "id": "1c8851ed"
   },
   "outputs": [],
   "source": [
    "X_b = np.hstack((np.ones([N,1]),X))\n",
    "theta = np.dot(np.dot(np.linalg.inv(np.dot(X_b.T,X_b)),X_b.T),y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0254dca",
   "metadata": {
    "id": "b0254dca"
   },
   "source": [
    "Lets plot everything again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc45f8",
   "metadata": {
    "id": "d3fc45f8"
   },
   "outputs": [],
   "source": [
    "X_new = np.linspace(0, 5, N).reshape(N, 1) # These are X-values we will use\n",
    "X_new_b = np.hstack((np.ones([N,1]), X_new)) # Add intercept\n",
    "y_hat_gd = np.dot(X_new_b, (theta0,theta1)) #\n",
    "y_hat = np.dot(X_new_b, theta)\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X_new, y_hat_gd, 'r', linewidth=3)\n",
    "plt.plot(X_new, y_hat, 'c', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d15a0",
   "metadata": {
    "id": "378d15a0"
   },
   "source": [
    "As we actually save the thetas we can plot the predictions given each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bcfca",
   "metadata": {
    "id": "f84bcfca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mplc\n",
    "plt.scatter(X,y)\n",
    "for i in range(n_epochs):\n",
    "    y_hat = np.dot(X_new_b, thetas[i,:])\n",
    "    color = mplc.rgb2hex(plt.cm.OrRd(i / n_epochs))\n",
    "    plt.plot(X_new, y_hat, linestyle=\"solid\", color=color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79f923",
   "metadata": {
    "id": "fd79f923"
   },
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
