{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35_2023/blob/main/Session6/BMEN35_ensamble_cinc_assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkiFi80bGKEc"
   },
   "source": [
    "# Assignment 6\n",
    "## Fill in your name below\n",
    "Alexander Andersson, BME4\n",
    "\n",
    "## Your mission is now the following:\n",
    "\n",
    "You will use data from the Computing in Cardiology challenge 2022 (as was explained in the lectures) (https://moody-challenge.physionet.org/2022/). The training set contains data from 942 patients.\n",
    "\n",
    "We have done some preprocessing of the data so you have features and labels for both **murmur** and **outcome**. The features include age, sex, weight, heigth, pregnancy status and mean, variance and skewness for the phonocardiogram at five different locations.\n",
    "\n",
    "Evaluate different ensamble methods (at least 3) from sklearn (https://scikit-learn.org/stable/modules/ensemble.html and https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble) and see how they perform on the CinC2022 challenge data. Take some time to read the documentation and see what options are available.\n",
    "\n",
    "As you may remember from the lecture there is quite an eloborate scoring scheme, however this is handled by the file cinc2022metric.py and the methods contained therein.\n",
    "\n",
    "**Also remeber you have two sets of labels!!! One set of labels for murmurs (Present, Unknown, Absent) and one for outcomes (Abnormal, Normal).**\n",
    "\n",
    "**Another thing you need to take into account is that the scoring functions need label probabilities of the predicted classes.**\n",
    "\n",
    "You will also need one-hot encoding of \"hard\" values for the training labels and for the test labels.\n",
    "\n",
    "We will start by uploading some files. You need to upload the files cinc2022metrics.py, feats.csv, murmur_labels.csv and outcome_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRiQuM1OHKQR"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "_ = files.upload() # Upload the other files available in github under Session 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YbyBrB9MKBW"
   },
   "source": [
    "Next we will import some of the libraries/modules needed. (You will need to import others later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 20.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 23.4 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading grpcio-1.59.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 181.3/181.3 kB ? eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sasyn\\anaconda3\\envs\\ml\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl (300.9 MB)\n",
      "   ---------------------------------------- 0.0/300.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/300.9 MB 30.1 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 2.4/300.9 MB 30.9 MB/s eta 0:00:10\n",
      "    --------------------------------------- 3.9/300.9 MB 31.1 MB/s eta 0:00:10\n",
      "    --------------------------------------- 5.2/300.9 MB 30.4 MB/s eta 0:00:10\n",
      "    --------------------------------------- 6.6/300.9 MB 32.6 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 8.3/300.9 MB 33.3 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 9.9/300.9 MB 31.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 11.4/300.9 MB 31.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 13.0/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 14.6/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 16.0/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 17.7/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 19.3/300.9 MB 31.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 20.6/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 22.1/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 23.5/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 25.4/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 26.7/300.9 MB 34.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 27.9/300.9 MB 34.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 29.6/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 31.3/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 32.8/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 34.4/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 35.8/300.9 MB 32.7 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 37.7/300.9 MB 32.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 39.1/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 40.7/300.9 MB 29.7 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 42.2/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 43.9/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 45.7/300.9 MB 32.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 47.5/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 48.4/300.9 MB 29.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 50.3/300.9 MB 31.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 51.9/300.9 MB 29.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 53.6/300.9 MB 29.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 55.3/300.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 56.7/300.9 MB 29.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 58.3/300.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 59.5/300.9 MB 31.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 61.4/300.9 MB 31.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 62.3/300.9 MB 29.8 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 63.3/300.9 MB 28.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 64.6/300.9 MB 28.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 65.9/300.9 MB 28.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 67.1/300.9 MB 28.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 68.1/300.9 MB 26.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 69.5/300.9 MB 27.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 71.0/300.9 MB 27.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 72.5/300.9 MB 27.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 74.3/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 75.9/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 76.2/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 76.2/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 76.2/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 76.2/300.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 77.0/300.9 MB 18.2 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 78.7/300.9 MB 19.3 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 80.4/300.9 MB 19.8 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 82.0/300.9 MB 20.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 83.7/300.9 MB 20.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 85.8/300.9 MB 21.8 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 87.5/300.9 MB 38.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 89.3/300.9 MB 38.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 91.7/300.9 MB 40.9 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 94.7/300.9 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 96.6/300.9 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 98.6/300.9 MB 50.4 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 100.3/300.9 MB 50.4 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 102.2/300.9 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 103.4/300.9 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 104.8/300.9 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 106.3/300.9 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 107.9/300.9 MB 36.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 109.3/300.9 MB 34.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 111.0/300.9 MB 34.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 112.7/300.9 MB 31.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 114.1/300.9 MB 32.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 115.4/300.9 MB 32.7 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 117.1/300.9 MB 34.4 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 118.7/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 120.0/300.9 MB 32.8 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 121.4/300.9 MB 32.8 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 122.8/300.9 MB 32.8 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 124.2/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 125.7/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 127.6/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 129.6/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 131.2/300.9 MB 29.8 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 132.6/300.9 MB 32.7 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 134.0/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 135.5/300.9 MB 32.8 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 136.8/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 138.3/300.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 139.8/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 141.5/300.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 143.4/300.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 145.0/300.9 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 146.3/300.9 MB 34.6 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 147.9/300.9 MB 36.3 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 149.6/300.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 150.9/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 152.4/300.9 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 154.0/300.9 MB 32.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 155.1/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 156.7/300.9 MB 32.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 158.2/300.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 159.3/300.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 160.2/300.9 MB 28.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 163.4/300.9 MB 31.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 164.9/300.9 MB 31.1 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 166.6/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 168.0/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 169.4/300.9 MB 32.8 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 171.3/300.9 MB 36.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 173.0/300.9 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 174.5/300.9 MB 32.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 176.1/300.9 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 177.4/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 179.0/300.9 MB 32.8 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 180.4/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 181.8/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 183.3/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 184.5/300.9 MB 28.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 185.9/300.9 MB 28.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 187.1/300.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 188.4/300.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 190.1/300.9 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 191.7/300.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 193.2/300.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 194.6/300.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 196.4/300.9 MB 32.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 197.6/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 199.0/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 200.5/300.9 MB 32.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 201.8/300.9 MB 31.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 203.1/300.9 MB 31.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 204.7/300.9 MB 29.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 206.1/300.9 MB 28.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 207.7/300.9 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 208.9/300.9 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 210.3/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 211.9/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 213.6/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 215.3/300.9 MB 29.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 217.1/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 218.1/300.9 MB 31.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 219.2/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 220.2/300.9 MB 29.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 221.3/300.9 MB 28.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 222.0/300.9 MB 25.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 223.6/300.9 MB 26.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 225.0/300.9 MB 25.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 226.5/300.9 MB 26.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 228.0/300.9 MB 26.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 229.6/300.9 MB 28.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 231.3/300.9 MB 29.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 232.5/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 233.8/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 235.2/300.9 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 236.5/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 238.2/300.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 240.0/300.9 MB 31.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 241.4/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 242.8/300.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 244.2/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 245.6/300.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 246.9/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 248.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 249.8/300.9 MB 29.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 251.2/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 253.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 254.4/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 256.0/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 257.6/300.9 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 259.0/300.9 MB 32.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 260.6/300.9 MB 32.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 261.7/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 263.0/300.9 MB 29.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 264.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 264.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 264.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 264.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 264.1/300.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 265.2/300.9 MB 19.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 267.2/300.9 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 269.4/300.9 MB 21.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 272.4/300.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 274.0/300.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 276.0/300.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 277.6/300.9 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 278.9/300.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 280.6/300.9 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 281.6/300.9 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 283.6/300.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 285.2/300.9 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.8/300.9 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 288.6/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 290.4/300.9 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 291.9/300.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  293.5/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  295.1/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  296.8/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  298.7/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.1/300.9 MB 31.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.9/300.9 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.2/130.2 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.59.3-cp311-cp311-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.1/3.7 MB 66.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.3/3.7 MB 42.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 33.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.4/2.7 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 33.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.7/1.7 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 27.0 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/24.4 MB 38.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.9/24.4 MB 30.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.2/24.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 6.8/24.4 MB 33.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.5/24.4 MB 33.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 9.7/24.4 MB 32.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.5/24.4 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.8/24.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.1/24.4 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.3/24.4 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.7/24.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.9/24.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.4/24.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.9/24.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.3/24.4 MB 31.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.5/24.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "   ---------------------------------------- 0.0/938.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 938.7/938.7 kB 30.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 33.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 33.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 33.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 33.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 33.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.5/5.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "   ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 422.5/422.5 kB 25.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "   ---------------------------------------- 0.0/442.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 442.0/442.0 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl (35 kB)\n",
      "Downloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "   ---------------------------------------- 0.0/183.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 183.3/183.3 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.2/102.2 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 226.7/226.7 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.9/84.9 kB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.59.3 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-3.0.1 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgS-HYV4MWn3"
   },
   "source": [
    "Next we will import data and the two different sets of labels and switch to numpy arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NXy1fcB8Mah0"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cinc2022metrics as cm # Our own little metrics file\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "feats = pd.read_csv('feats.csv', header=None)\n",
    "murmur_labels = pd.read_csv('murmur_labels.csv', header=None)\n",
    "outcome_labels = pd.read_csv('outcome_labels.csv', header=None)\n",
    "\n",
    "feats = feats.to_numpy()\n",
    "\n",
    "murmur_labels = murmur_labels.to_numpy()\n",
    "outcome_labels = outcome_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6AjJag6bbYG"
   },
   "source": [
    "Here we will split the data and also define what the different classes for murmur and outcome are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DYFYliDGNCl0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_murmur, y_test_murmur, y_train_outcome, y_test_outcome = train_test_split(feats, murmur_labels, outcome_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Abnormal', 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abnormal', 'Normal']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x267218c3650>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "XX = np.linspace(0,100,len(feats[25]))\n",
    "yy = feats[0]\n",
    "plt.plot(XX, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AaRI3joNGvd"
   },
   "source": [
    "Next you can try out some of the available ensemble methods. Remember you need to predict probabilities for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[0,:] , y_test_outcome[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "murmur_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# clf = AdaBoostClassifier(n_estimators=10)\n",
    "# scores = cross_val_score(clf, X_train, y_train_murmur[:,0], cv=5)\n",
    "# scores.mean()\n",
    "# clf.fit(y_train_murmur,y_train_murmur[:,0] )\n",
    "\n",
    "# y_pred_murmur_prob = clf.predict_proba(y_test_murmur)\n",
    "# y_test_murmur_bin = to_categorical(y_test_murmur[:,0])\n",
    "\n",
    "\n",
    "import cinc2022metrics as cm \n",
    "\n",
    "class train_and_evaluate():\n",
    "\n",
    "    def __init__(self, clf, data,):\n",
    "        self.clf = clf\n",
    "        self.X_train = data[0]\n",
    "        self.y_train_murmur = data[1]\n",
    "        self.y_train_outcome = data[2]\n",
    "        self.X_test = data[3]\n",
    "        self.y_test_murmur = data[4]\n",
    "        self.y_test_outcome = data[5]\n",
    "\n",
    "    def to_categorical(self ,y):\n",
    "        y_cat = np.zeros( [len(y) , max(y)+1])\n",
    "        for indy , indcat  in enumerate(y):\n",
    "            y_cat[indy , indcat]=1\n",
    "        return y_cat\n",
    "    \n",
    "    def eval(self, print_sc):\n",
    "        self.clf.fit(self.X_train,self.y_train_murmur )  \n",
    "        y_pred_murmur_prob = self.clf.predict_proba(self.X_test)\n",
    "        y_test_murmur_bin = self.to_categorical(self.y_test_murmur)\n",
    "\n",
    "        \n",
    "        self.clf.fit(self.X_train,self.y_train_outcome )\n",
    "        y_pred_outcome_prob = self.clf.predict_proba(self.X_test )\n",
    "        y_test_outcome_bin  = self.to_categorical(self.y_test_outcome)\n",
    "\n",
    "        \n",
    "        murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
    "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]\n",
    "                                                  murmur_classes,      # As defined before\n",
    "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
    "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
    "                                                  outcome_classes)     # As defined before\n",
    "        return (murmur_scores ,outcome_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "FT0zGggANGIW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247972011492691\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.520,0.344,0.277,0.709,0.647,14560.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.637,0.607,0.617,0.619,0.602,12335.966\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.446,0.523,0.590\n",
      "AUPRC,0.191,0.731,0.110\n",
      "F-measure,0.000,0.832,0.000\n",
      "Accuracy,0.000,0.985,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.637,0.637\n",
      "AUPRC,0.581,0.633\n",
      "F-measure,0.586,0.647\n",
      "Accuracy,0.593,0.641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=10)\n",
    "data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[:,0] , y_test_outcome[:,0])\n",
    "tr_ev = train_and_evaluate(clf, data) \n",
    "murmur_scores ,outcome_scores = tr_ev.eval()\n",
    "mean_score  = (murmur_scores[-2]+outcome_scores[-2])/2\n",
    "#cm.print_scores(murmur_scores , outcome_scores)   \n",
    "print(mean_score)\n",
    "\n",
    "cm.print_scores(murmur_scores ,outcome_scores)\n",
    "# we want to maximize the weighted avrage accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [01:05<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "results = {}\n",
    "for i in tqdm(range(10,200, 10)):\n",
    "    m = []\n",
    "    clf = GradientBoostingClassifier(n_estimators = i)\n",
    "    #data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[:,0] , y_test_outcome[:,0])\n",
    "    tr_ev = train_and_evaluate(clf, data) \n",
    "    murmur_scores ,outcome_scores = tr_ev.eval()\n",
    "    mean_score  = (murmur_scores[-2]+outcome_scores[-2])/2\n",
    "    m.append(mean_score)\n",
    "    #cm.print_scores(murmur_scores , outcome_scores)  \n",
    "        \n",
    "    results[i] = np.mean(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.6459743861652663,\n",
       " 20: 0.6304257189729088,\n",
       " 30: 0.6323018915807888,\n",
       " 40: 0.6345768641632905,\n",
       " 50: 0.6410180879958187,\n",
       " 60: 0.628283679715281,\n",
       " 70: 0.6324348249056626,\n",
       " 80: 0.6359213034716746,\n",
       " 90: 0.6277519464157852,\n",
       " 100: 0.6289634523992954,\n",
       " 110: 0.622248808887197,\n",
       " 120: 0.626540440432275,\n",
       " 130: 0.6190357500007553,\n",
       " 140: 0.6183559773167409,\n",
       " 150: 0.6108512868852212,\n",
       " 160: 0.617019091038179,\n",
       " 170: 0.6187547772913626,\n",
       " 180: 0.6124615928433532,\n",
       " 190: 0.6329741112349808}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247972011492691\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.520,0.344,0.277,0.709,0.647,14560.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.637,0.607,0.617,0.619,0.602,12335.966\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.446,0.523,0.590\n",
      "AUPRC,0.191,0.731,0.110\n",
      "F-measure,0.000,0.832,0.000\n",
      "Accuracy,0.000,0.985,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.637,0.637\n",
      "AUPRC,0.581,0.633\n",
      "F-measure,0.586,0.647\n",
      "Accuracy,0.593,0.641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=10)\n",
    "data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[:,0] , y_test_outcome[:,0])\n",
    "tr_ev = train_and_evaluate(clf, data) \n",
    "murmur_scores ,outcome_scores = tr_ev.eval()\n",
    "mean_score  = (murmur_scores[-2]+outcome_scores[-2])/2\n",
    "#cm.print_scores(murmur_scores , outcome_scores)   \n",
    "print(mean_score)\n",
    "\n",
    "cm.print_scores(murmur_scores ,outcome_scores)\n",
    "# we want to maximize the weighted avrage accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cost is higher when using the gradient boosting method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [01:28<00:00,  4.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "results = {}\n",
    "for i in tqdm(range(10,200, 10)):\n",
    "    m = []\n",
    "    for j in range(0,5):\n",
    "        clf = RandomForestClassifier(n_estimators = i)\n",
    "        #data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[:,0] , y_test_outcome[:,0])\n",
    "        tr_ev = train_and_evaluate(clf, data) \n",
    "        murmur_scores ,outcome_scores = tr_ev.eval()\n",
    "        mean_score  = (murmur_scores[-2]+outcome_scores[-2])/2\n",
    "        m.append(mean_score)\n",
    "        #cm.print_scores(murmur_scores , outcome_scores)  \n",
    "        \n",
    "    results[i] = np.mean(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.6459743861652663,\n",
       " 20: 0.6304257189729088,\n",
       " 30: 0.6323018915807888,\n",
       " 40: 0.6345768641632905,\n",
       " 50: 0.6410180879958187,\n",
       " 60: 0.628283679715281,\n",
       " 70: 0.6324348249056626,\n",
       " 80: 0.6359213034716746,\n",
       " 90: 0.6277519464157852,\n",
       " 100: 0.6289634523992954,\n",
       " 110: 0.622248808887197,\n",
       " 120: 0.626540440432275,\n",
       " 130: 0.6190357500007553,\n",
       " 140: 0.6183559773167409,\n",
       " 150: 0.6108512868852212,\n",
       " 160: 0.617019091038179,\n",
       " 170: 0.6187547772913626,\n",
       " 180: 0.6124615928433532,\n",
       " 190: 0.6329741112349808}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-meas,Accuracy,Weighted Accuracy,Cost\n",
      "0.573,0.369,0.278,0.714,0.652,14560.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.637,0.637,0.640,0.640,0.662,11071.686\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.563,0.579,0.576\n",
      "AUPRC,0.236,0.784,0.088\n",
      "F-measure,0.000,0.833,0.000\n",
      "Accuracy,0.000,0.993,0.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.637,0.637\n",
      "AUPRC,0.620,0.654\n",
      "F-measure,0.630,0.649\n",
      "Accuracy,0.674,0.612\n",
      "\n",
      "0.6572314218125459\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 180)\n",
    "#data = (X_train , y_train_murmur[:,0], y_train_outcome[:,0] , X_test, y_test_murmur[:,0] , y_test_outcome[:,0])\n",
    "tr_ev = train_and_evaluate(clf, data) \n",
    "murmur_scores ,outcome_scores = tr_ev.eval()\n",
    "mean_score  = (murmur_scores[-2]+outcome_scores[-2])/2\n",
    "cm.print_scores(murmur_scores , outcome_scores)\n",
    "print(mean_score)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MzLjkQXb0-d"
   },
   "source": [
    "Now you should also One-hot encode the **test** (not the predicted ones) labels for both murmur and outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "E0LHwnQUb0fV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Present', 'Unknown', 'Absent'], 0.5197484503971425, 0.344059540679111, array([0.44630872, 0.52268313, 0.5902535 ]), array([0.19058707, 0.7313269 , 0.11026465]), 0.2774327122153209, array([0.        , 0.83229814, 0.        ]), 0.708994708994709, array([0.        , 0.98529412, 0.        ]), 0.6473429951690821, 14560.26455026455)\n"
     ]
    }
   ],
   "source": [
    "print(murmur_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T91QCcRgcl9T"
   },
   "source": [
    "Now we have calculated a whole bunch of scores for both murmur and outcome. We can print them using the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGczxkWWR50z"
   },
   "source": [
    "Did you manage to comparable scores to those in the leaderboard as shown in the last slide of the lecture? (It should be noted that we don't have the validation data so we are perhaps comparing apples and oranges). Which set of ensemble classifiers worked the best?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5zNz7eZeSvC"
   },
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
